{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HEK Quickstart\n",
        "\n",
        "Run a minimal MLflow-backed evaluation and log HEK metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from src.modules.evaluation import ModelEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "mlflow.set_experiment(\"hek-notebook-quickstart\")\n",
        "\n",
        "X = pd.DataFrame({\"x1\": [0, 0, 1, 1], \"x2\": [0, 1, 0, 1]})\n",
        "y = pd.Series([0, 0, 1, 1])\n",
        "model = LogisticRegression().fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with mlflow.start_run(run_name=\"quickstart\") as run:\n",
        "    mlflow.set_tag(\"hokusai.eval_id\", \"quickstart-v1\")\n",
        "    mlflow.set_tag(\"hokusai.model_id\", \"demo-model\")\n",
        "    mlflow.set_tag(\"hokusai.primary_metric\", \"accuracy\")\n",
        "    mlflow.set_tag(\"hokusai.dataset.id\", \"toy-dataset\")\n",
        "    mlflow.set_tag(\"hokusai.dataset.hash\", \"sha256:\" + \"a\" * 64)\n",
        "    mlflow.set_tag(\"hokusai.dataset.num_samples\", str(len(X)))\n",
        "\n",
        "    evaluator = ModelEvaluator(metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"auroc\"])\n",
        "    metrics = evaluator.evaluate_sklearn_model(model, X, y)\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        if metric_value is not None:\n",
        "            mlflow.log_metric(metric_name, float(metric_value))\n",
        "\n",
        "print(run.info.run_id)\n",
        "print(metrics)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
